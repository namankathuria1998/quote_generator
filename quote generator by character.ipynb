{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "import sys\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input, Activation, Dense, Dropout\n",
    "from keras.layers import LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotables = pd.read_csv('author-quote.txt', delimiter='\\t', header=None)\n",
    "quotables = quotables.rename(columns={0:'author', 1:'quote'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>Education is what remains after one has forgot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6162</th>\n",
       "      <td>Charles R. Jackson</td>\n",
       "      <td>The writer knows his own worth, and to be over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29535</th>\n",
       "      <td>Robert H. Schuller</td>\n",
       "      <td>Anyone can count the seeds in an apple, but on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25907</th>\n",
       "      <td>Muhammad Ali Jinnah</td>\n",
       "      <td>With faith, discipline and selfless devotion t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21890</th>\n",
       "      <td>Lee H. Hamilton</td>\n",
       "      <td>U.S. officials and outside experts agree that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11896</th>\n",
       "      <td>Frederik, Crown Prince of Denmark</td>\n",
       "      <td>I am just an apprentice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502</th>\n",
       "      <td>Carl Sandburg</td>\n",
       "      <td>Slang is a language that rolls up its sleeves,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>Anita Baker</td>\n",
       "      <td>I'd love to be the political voice of my gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>Clare Balding</td>\n",
       "      <td>I want to make the world a better place, for w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34206</th>\n",
       "      <td>Tyler Hamilton</td>\n",
       "      <td>If you look at my career, I kind of got progre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>Bo Jackson</td>\n",
       "      <td>I've always played with kids that were five, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>Andy Rooney</td>\n",
       "      <td>Obscenities... I think a lot of dumb people do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32073</th>\n",
       "      <td>Stephen Covey</td>\n",
       "      <td>Trust is the glue of life. It's the most essen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21851</th>\n",
       "      <td>Lawrence Ferlinghetti</td>\n",
       "      <td>Well, I didn't know how to draw very well back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31287</th>\n",
       "      <td>Shawn Fanning</td>\n",
       "      <td>It was very early, and we were still like beta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17723</th>\n",
       "      <td>Jim Balsillie</td>\n",
       "      <td>In spite of all this noise, customers are stil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10164</th>\n",
       "      <td>Elizabeth Barrett Browning</td>\n",
       "      <td>Smiles, tears, of all my life! - and, if God c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18916</th>\n",
       "      <td>John Galsworthy</td>\n",
       "      <td>The French cook; we open tins.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17925</th>\n",
       "      <td>Jim Valvano</td>\n",
       "      <td>And if you see me, smile and maybe give me a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35538</th>\n",
       "      <td>William Hazlitt</td>\n",
       "      <td>A gentle word, a kind look, a good-natured smi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  author  \\\n",
       "868                      Albert Einstein   \n",
       "6162                  Charles R. Jackson   \n",
       "29535                 Robert H. Schuller   \n",
       "25907                Muhammad Ali Jinnah   \n",
       "21890                    Lee H. Hamilton   \n",
       "11896  Frederik, Crown Prince of Denmark   \n",
       "5502                       Carl Sandburg   \n",
       "2204                         Anita Baker   \n",
       "7083                       Clare Balding   \n",
       "34206                     Tyler Hamilton   \n",
       "4288                          Bo Jackson   \n",
       "2107                         Andy Rooney   \n",
       "32073                      Stephen Covey   \n",
       "21851              Lawrence Ferlinghetti   \n",
       "31287                      Shawn Fanning   \n",
       "17723                      Jim Balsillie   \n",
       "10164         Elizabeth Barrett Browning   \n",
       "18916                    John Galsworthy   \n",
       "17925                        Jim Valvano   \n",
       "35538                    William Hazlitt   \n",
       "\n",
       "                                                   quote  \n",
       "868    Education is what remains after one has forgot...  \n",
       "6162   The writer knows his own worth, and to be over...  \n",
       "29535  Anyone can count the seeds in an apple, but on...  \n",
       "25907  With faith, discipline and selfless devotion t...  \n",
       "21890  U.S. officials and outside experts agree that ...  \n",
       "11896                           I am just an apprentice.  \n",
       "5502   Slang is a language that rolls up its sleeves,...  \n",
       "2204   I'd love to be the political voice of my gener...  \n",
       "7083   I want to make the world a better place, for w...  \n",
       "34206  If you look at my career, I kind of got progre...  \n",
       "4288   I've always played with kids that were five, s...  \n",
       "2107   Obscenities... I think a lot of dumb people do...  \n",
       "32073  Trust is the glue of life. It's the most essen...  \n",
       "21851  Well, I didn't know how to draw very well back...  \n",
       "31287  It was very early, and we were still like beta...  \n",
       "17723  In spite of all this noise, customers are stil...  \n",
       "10164  Smiles, tears, of all my life! - and, if God c...  \n",
       "18916                     The French cook; we open tins.  \n",
       "17925  And if you see me, smile and maybe give me a h...  \n",
       "35538  A gentle word, a kind look, a good-natured smi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotables.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotables['len_quotes'] = quotables.quote.map(lambda s: len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quotes = list(quotables.quote + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_char = ['#', '$', '%', '(', ')', '=', ';' ,':',  '*', '+', '£' , '—','’']  \n",
    "quotes_cleaned = []\n",
    "\n",
    "for quote in quotes: \n",
    "    # remove unused character\n",
    "    for s_char in removed_char:\n",
    "        quote = quote.replace(s_char, ' ')\n",
    "    \n",
    "    # remove white space\n",
    "    pattern = re.compile(r'\\s{2,}')\n",
    "    quote = re.sub(pattern, ' ', quote)\n",
    "\n",
    "    quotes_cleaned.append(quote)\n",
    "\n",
    "text = ' '.join(quotes_cleaned)\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 753142\n"
     ]
    }
   ],
   "source": [
    "maxlen = 15\n",
    "step = 6\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for quote in quotes_cleaned:\n",
    "    for i in range(0, len(quote) - maxlen, step):\n",
    "        sentences.append(quote[i: i + maxlen])\n",
    "        next_chars.append(quote[i + maxlen])\n",
    "    sentences.append(quote[-maxlen:])\n",
    "    next_chars.append(quote[-1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If you live to ',\n",
       " ' live to be a h',\n",
       " 'to be a hundred',\n",
       " 'a hundred, I wa',\n",
       " 'red, I want to ',\n",
       " ' want to live t',\n",
       " 'to live to be a',\n",
       " 'e to be a hundr',\n",
       " 'e a hundred min',\n",
       " 'ndred minus one',\n",
       " 'minus one day s',\n",
       " 'one day so I ne',\n",
       " 'y so I never ha',\n",
       " ' never have to ',\n",
       " ' have to live w',\n",
       " 'to live without',\n",
       " 'e without you.\\n',\n",
       " \"Promise me you'\",\n",
       " \"e me you'll alw\",\n",
       " \"ou'll always re\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((753142, 15, 73), (753142, 73), 73)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "## Model \n",
    "print('Build model...')\n",
    "input_sequences = Input((maxlen, len(chars)) , name=\"input_sequences\")\n",
    "lstm = Bidirectional(LSTM(256, return_sequences= True, input_shape=(maxlen, len(chars))), name = 'bidirectional')(input_sequences)\n",
    "lstm = Dropout(0.1, name = 'dropout_bidirectional_lstm')(lstm)\n",
    "lstm = LSTM(64, input_shape=(maxlen, len(chars)), name = 'lstm')(lstm)\n",
    "lstm = Dropout(0.1,  name = 'drop_out_lstm')(lstm)\n",
    "\n",
    "dense = Dense(15 * len(chars), name = 'first_dense')(lstm)\n",
    "dense = Dropout(0.1,  name = 'drop_out_first_dense')(dense)\n",
    "dense = Dense(5 * len(chars), name = 'second_dense')(dense)\n",
    "dense = Dropout(0.1,  name = 'drop_out_second_dense')(dense)\n",
    "dense = Dense(len(chars), name = 'last_dense')(dense)\n",
    "\n",
    "next_char = Activation('softmax', name = 'activation')(dense)\n",
    "\n",
    "model = Model([input_sequences], next_char)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_sequences (InputLayer) (None, 15, 73)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 15, 512)           675840    \n",
      "_________________________________________________________________\n",
      "dropout_bidirectional_lstm ( (None, 15, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                147712    \n",
      "_________________________________________________________________\n",
      "drop_out_lstm (Dropout)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "first_dense (Dense)          (None, 1095)              71175     \n",
      "_________________________________________________________________\n",
      "drop_out_first_dense (Dropou (None, 1095)              0         \n",
      "_________________________________________________________________\n",
      "second_dense (Dense)         (None, 365)               400040    \n",
      "_________________________________________________________________\n",
      "drop_out_second_dense (Dropo (None, 365)               0         \n",
      "_________________________________________________________________\n",
      "last_dense (Dense)           (None, 73)                26718     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 73)                0         \n",
      "=================================================================\n",
      "Total params: 1,321,485\n",
      "Trainable params: 1,321,485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "753142/753142 [==============================] - 1232s 2ms/step - loss: 1.8665\n",
      "Epoch 2/15\n",
      "753142/753142 [==============================] - 1282s 2ms/step - loss: 1.5284\n",
      "Epoch 3/15\n",
      "753142/753142 [==============================] - 1276s 2ms/step - loss: 1.4250\n",
      "Epoch 4/15\n",
      "753142/753142 [==============================] - 1278s 2ms/step - loss: 1.3667\n",
      "Epoch 5/15\n",
      "753142/753142 [==============================] - 1247s 2ms/step - loss: 1.3270\n",
      "Epoch 6/15\n",
      "753142/753142 [==============================] - 1199s 2ms/step - loss: 1.2970\n",
      "Epoch 7/15\n",
      "753142/753142 [==============================] - 1202s 2ms/step - loss: 1.2734\n",
      "Epoch 8/15\n",
      "753142/753142 [==============================] - 1197s 2ms/step - loss: 1.2530\n",
      "Epoch 9/15\n",
      "753142/753142 [==============================] - 1195s 2ms/step - loss: 1.2353\n",
      "Epoch 10/15\n",
      "753142/753142 [==============================] - 1191s 2ms/step - loss: 1.2198\n",
      "Epoch 11/15\n",
      "753142/753142 [==============================] - 1187s 2ms/step - loss: 1.2054\n",
      "Epoch 12/15\n",
      "753142/753142 [==============================] - 1182s 2ms/step - loss: 1.1925\n",
      "Epoch 13/15\n",
      "753142/753142 [==============================] - 1178s 2ms/step - loss: 1.1799\n",
      "Epoch 14/15\n",
      "753142/753142 [==============================] - 1187s 2ms/step - loss: 1.1690\n",
      "Epoch 15/15\n",
      "753142/753142 [==============================] - 1198s 2ms/step - loss: 1.1591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c3891d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x], y,\n",
    "         batch_size=128,\n",
    "          epochs= 15\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "753142/753142 [==============================] - 959s 1ms/step - loss: 1.0823\n",
      "Epoch 2/2\n",
      "753142/753142 [==============================] - 1106s 1ms/step - loss: 1.0619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x162988f60>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x], y,\n",
    "         batch_size=2048,\n",
    "          epochs= 2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "753142/753142 [==============================] - 969s 1ms/step - loss: 1.0616\n",
      "Epoch 2/2\n",
      "753142/753142 [==============================] - 980s 1ms/step - loss: 1.0574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c389208>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x], y,\n",
    "         batch_size=1024,\n",
    "          epochs= 2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_first_words = [bigram for bigram in [' '.join(word_tokenize(quote)[:2]) for quote in quotes] if len(bigram) <= maxlen]\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quote(sentence = None, diversity = 0.8):\n",
    "    \n",
    "    if not sentence: ## if input is null then sample two first word from dataset\n",
    "        random_index = np.random.randint(0, len(two_first_words))\n",
    "        sentence = two_first_words[random_index]\n",
    "        \n",
    "    if len(sentence) > maxlen:\n",
    "        sentence = sentence[-maxlen:]\n",
    "    elif len(sentence) < maxlen:\n",
    "        sentence = ' '*(maxlen - len(sentence)) + sentence\n",
    "        \n",
    "    generated = ''\n",
    "    generated += sentence\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    next_char = 'Empty'\n",
    "    total_word = 0 \n",
    "    \n",
    "    max_word = 15\n",
    "    \n",
    "    while ((next_char not in ['\\n', '.']) & (total_word <= 500)):\n",
    "    \n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        if next_char == ' ':\n",
    "           total_word += 1\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        I couldn't walk in the church.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         You don't have to take on my family.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      The legal songs on the same credit the long time, and you love a man without love, understanding.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Learn to know what the issue is my universe, how you do what they instead of beow.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       My motto with the down and amazing state in the classic and face it because I was a DeficiI I would learn all the unity.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       There is nothing without the past.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     After much things that I had a good way to be able to place the material things in the form of our tatence will go to see their show in it.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Once you will love you so introversions who'll say there is important thing that are something good into something to be simpling my feet I could be a none is the real of a time to stand for video from an energy people.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A successful sadness of the game of our controversy for how hear, is wrong in the time, and I got a short men.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Happiness is so such a house why can hasten before, what you take every time with my encouraged by Phose.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         If you are too lack friends and his things that are well in a books are not the volution of its heart that is a movie the banda used to always be a wanting to be long is confidentally good to one would be much more believe I do your poor.\n"
     ]
    }
   ],
   "source": [
    "generate_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_char.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_char.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
